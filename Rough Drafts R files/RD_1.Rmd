---
title: "project101"
output: html_document
date: "2022-12-04"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ezids)
library(ggplot2)
library(dplyr)
library(corrplot)
library(caret)
library(rpart)
library(rpart.plot)
library(DAAG)
library(party)
library(mlbench)
library(caret)
library(pROC)
library(tree)
library(randomForest)
```

## SMART QUESTION

### Does the age at which adolescents start engaging in "deviant" behaviors predict their interpersonal, physical, and mental well-being? Furthermore, how does race influence interpersonal, physical, and mental well-being?


```{r cars}
dataset = read.csv("../sadc_df.csv")
# select variables v1, v2, v3
myvars <- c("Age_Alc", "Age_Weed","multiple_partners","physical_activity","Hrs_Sleep","age_sex","race","gender","fight","suicide")
data <- dataset[myvars]
data <- data[data$age_sex != 0,]
```

```{r}
loadPkg("ggplot2")
data$Age_Alc <- as.factor(data$Age_Alc)
ggplot(data, aes(x=Age_Alc, y=Hrs_Sleep)) + 
  geom_boxplot(outlier.shape = NA) +
  labs(title="Hours of Sleep By Age when First started Drinking")
```
```{r}
data$Age_Alc <- as.factor(data$Age_Alc)
ggplot(data, aes(x=Age_Alc, y=multiple_partners)) + 
  geom_boxplot(outlier.shape = NA) +
  labs(title="Number of Partners when First started Drinking")
```
```{r}
# select numeric variables
df <- dplyr::select_if(data, is.numeric)

# calculate the correlations
r <- cor(df, use="complete.obs")
round(r,2)
```


```{r}
data$fight1 <- recode(data$fight, '0' = 1, '1' = 0)
data$suicide1 <- recode(data$suicide, '0' = 1, '1' = 0)

```

## Including Plots

```{r}
summary(data)
data$gender <- as.factor(data$gender)
data$race <- as.factor(data$race)
data$suicide1 <- as.factor(data$suicide1)
data$fight1 <- as.factor(data$fight1)
data$Age_Alc <- as.numeric(data$Age_Alc)
```



Question 1 - Logistic Regression 

```{r}

set.seed(920)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata1  <- data[sample, ]
testdata1   <- data[!sample, ]


model1a<-glm(formula = fight1 ~ Age_Weed + Age_Alc + age_sex + race , family = "binomial", data = traindata1)

summary(model1a)

plot(model1a)


testdata1$modelPredicted1a <- predict(model1a, newdata = testdata1, type = 'response')
testdata1

confusionMatrix(as.factor(as.numeric(testdata1$modelPredicted1a>0.55)), testdata1$fight1)
# 
# testdata1 <- testdata1  %>% mutate(model_pred1a = 1*(modelPredicted1a > .55) + 0)
# 
# testdata1 <- testdata1 %>% mutate(accurate1a = 1*(model_pred1a == fight1))
# Model1aAccuracyPercentage <- (sum(testdata1$accurate1)/nrow(testdata1))*100
# Model1aAccuracyPercentage
# print(paste0("Model accuracy percentage: ", Model1aAccuracyPercentage))
# 
# 
# confMat1 <- table(reference = testdata1$fight1, data = testdata1$modelPredicted1a > 0.55)
# confMat1

# Predict test data based on model
predict_reg <- predict(model1a, 
                       testdata1, type = "response")
predict_reg  
   
# Changing probabilities
predict_reg <- ifelse(predict_reg >0.5, 1, 0)
   
# Evaluating model accuracy
# using confusion matrix
table(testdata1$fight1, predict_reg)
   
missing_classerr <- mean(predict_reg != testdata1$fight1)
print(paste('Accuracy =', 1 - missing_classerr))

# ROC-AUC Curve
ROCPred <- prediction(predict_reg, testdata1$fight1) 
ROCPer <- performance(ROCPred, measure = "tpr", 
                             x.measure = "fpr")
   
auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
auc
   
# Plotting curve
plot(ROCPer)
plot(ROCPer, colorize = TRUE, 
     print.cutoffs.at = seq(0.1, by = 0.1), 
     main = "ROC CURVE")
abline(a = 0, b = 1)
   
auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)
```

Question 1b - Decision Tree------------ 

```{r}

set.seed(920)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata1  <- data[sample, ]
testdata1   <- data[!sample, ]

model1b<-rpart(formula = fight1 ~ Age_Weed + Age_Alc + age_sex + race , data = traindata1, method = 'class')

rpart.plot(model1b, extra = 106)



testdata1$modelPredicted1b <-predict(model1b, testdata1, type = 'class')

table1b <- confusionMatrix(testdata1$modelPredicted1b, testdata1$fight1, positive='1')
table1b

printcp(model1b)
plotcp(model1b)


rpart.rules(model1b)

### plotting ROC curve and calculating AUC metric

#predictionswithProbs<- predict(model1b, testdata1, type = 'prob')
#auc<-auc(testdata1$fight1,predictionswithProbs[,2])
#plot(roc(testdata1$fight1,predictionswithProbs[,2]))


DTPrediction <- predict(model1b, testdata1,type = "prob")
Prediction <- prediction(DTPrediction[,2],testdata1$fight1)
performance <- performance(Prediction, "tpr","fpr")
# plotting ROC curve
plot(performance,main = "ROC Curve",col = 2,lwd = 2)
abline(a = 0,b = 1,lwd = 2,lty = 3,col = "black")

#AUC
DTPrediction <- prediction(DTPrediction[,2],testdata1$fight1)
aucDT <- performance(DTPrediction, measure = "auc")
aucDT <- aucDT@y.values[[1]]
aucDT
```

Question 1c - Random Forest ------------ 

```{r}

set.seed(920)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata1  <- data[sample, ]
testdata1   <- data[!sample, ]

model1c<-randomForest(formula = fight1 ~ Age_Weed + Age_Alc + age_sex + race , data = traindata1, proximity=TRUE, type='classification', na.action=na.exclude)
print(model1c)

testdata1$modelPredicted1c <-predict(model1c, testdata1)

confusionMatrix(testdata1$fight1, testdata1$modelPredicted1c)

plot(model1c)

### plotting ROC curve and calculating AUC metric
DTPrediction1 <- predict(model1c, testdata1,type = "prob")
Prediction <- prediction(DTPrediction1[,2],testdata1$fight1)
performance <- performance(Prediction, "tpr","fpr")
# plotting ROC curve
plot(performance,main = "ROC Curve",col = 2,lwd = 2)
abline(a = 0,b = 1,lwd = 2,lty = 3,col = "black")

#AUC
DTPrediction1 <- prediction(DTPrediction1[,2],testdata1$fight1)
aucDT <- performance(DTPrediction1, measure = "auc")
aucDT <- aucDT@y.values[[1]]
aucDT
```


Question 2


```{r}
set.seed(927)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata2  <- data[sample, ]
testdata2   <- data[!sample, ]

model2a<-glm(formula = suicide1 ~ Age_Weed + Age_Alc + age_sex + race , family = "binomial", data = traindata2)

summary(model2a)
plot(model2a)



testdata2$modelPredicted2a <- predict(model2a, newdata = testdata2, type = 'response')


confusionMatrix(as.factor(as.numeric(testdata2$modelPredicted2a>0.55)), testdata2$suicide1)

# testdata2 <- testdata2  %>% mutate(model_pred2a = 1*(modelPredicted2a > .55) + 0)
# 
# testdata2 <- testdata2 %>% mutate(accurate2a = 1*(model_pred2a == suicide1))
# Model2aAccuracyPercentage <- (sum(testdata2$accurate2)/nrow(testdata2))*100
# Model2aAccuracyPercentage
# print(paste0("Model accuracy percentage: ", Model2aAccuracyPercentage))
# 
# 
# confMat2 <- table(testdata2$suicide1, testdata2$modelPredicted2a > 0.55)
# confMat2

# Predict test data based on model
predict_reg <- predict(model2a, 
                       testdata2, type = "response")
predict_reg  
   
# Changing probabilities
predict_reg <- ifelse(predict_reg >0.5, 1, 0)
   
# Evaluating model accuracy
# using confusion matrix
table(testdata2$suicide1, predict_reg)
   
missing_classerr <- mean(predict_reg != testdata2$suicide1)
print(paste('Accuracy =', 1 - missing_classerr))

# ROC-AUC Curve
ROCPred <- prediction(predict_reg, testdata2$suicide1) 
ROCPer <- performance(ROCPred, measure = "tpr", 
                             x.measure = "fpr")
   
auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
auc
   
# Plotting curve
plot(ROCPer)
plot(ROCPer, colorize = TRUE, 
     print.cutoffs.at = seq(0.1, by = 0.1), 
     main = "ROC CURVE")
abline(a = 0, b = 1)
   
auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)
```

Question 2b - Decision Tree ----------------------

```{r}

set.seed(927)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata2  <- data[sample, ]
testdata2   <- data[!sample, ]

model2b<-rpart(formula = suicide1 ~ Age_Weed + Age_Alc + age_sex + race , data = traindata2, method = 'class')

rpart.plot(model2b, extra = 106)
rpart.plot(model2b, extra = 106, type = 1)



testdata2$modelPredicted2b <-predict(model2b, testdata2, type = 'class')

table2b <- confusionMatrix(testdata2$modelPredicted2b, testdata1$suicide1, positive='1')
table2b

printcp(model2b)
plotcp(model2b)

rpart.rules(model2b)

### plotting ROC curve and calculating AUC metric
DTPrediction <- predict(model2b, testdata1,type = "prob")
Prediction <- prediction(DTPrediction[,2],testdata1$suicide1)
performance <- performance(Prediction, "tpr","fpr")
# plotting ROC curve
plot(performance,main = "ROC Curve",col = 2,lwd = 2)
abline(a = 0,b = 1,lwd = 2,lty = 3,col = "black")

#AUC
DTPrediction <- prediction(DTPrediction[,2],testdata1$suicide1)
aucDT <- performance(DTPrediction, measure = "auc")
aucDT <- aucDT@y.values[[1]]
aucDT
```

Question 2c - Random Forest ------------ 

```{r}

set.seed(920)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata2  <- data[sample, ]
testdata2   <- data[!sample, ]

model2c<-randomForest(formula = suicide1 ~ Age_Weed + Age_Alc + age_sex + race , data = traindata2, proximity=TRUE, type='classification', na.action=na.exclude)
print(model2c)

testdata2$modelPredicted2c <-predict(model2c, testdata2)

confusionMatrix(testdata2$suicide1, testdata2$modelPredicted2c)

plot(model2c)

### plotting ROC curve and calculating AUC metric
DTPrediction1 <- predict(model2c, testdata1,type = "prob")
Prediction <- prediction(DTPrediction1[,2],testdata1$suicide1)
performance <- performance(Prediction, "tpr","fpr")
# plotting ROC curve
plot(performance,main = "ROC Curve",col = 2,lwd = 2)
abline(a = 0,b = 1,lwd = 2,lty = 3,col = "black")

#AUC
DTPrediction1 <- prediction(DTPrediction1[,2],testdata1$suicide1)
aucDT <- performance(DTPrediction1, measure = "auc")
aucDT <- aucDT@y.values[[1]]
aucDT

```

Question 3 - 

```{r}

set.seed(997)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata3  <- data[sample, ]
testdata3   <- data[!sample, ]


model3a <- lm(Hrs_Sleep ~  Age_Alc + Age_Weed + age_sex + race, data=traindata3)

summary(model3a)

xkabledply(model3a, title = paste("Model :", format(formula(model3a)) ) )
xkablevif(model3a)


testdata3$modelPredicted3a <- predict(model3a, newdata = testdata3)
testdata3

# RESIDUALS ANALYSIS
# 
qqnorm(residuals(model3a))
qqline(residuals(model3a), col="red")

# shapiro.test(residuals(lm.fit))

# EVALUATE THE QUALITY OF THE MODEL
# 

# create a random training and a testing set
set.seed(1)
row.number <- sample(1:nrow(data), 0.8*nrow(data))

train <- data[row.number,]
test <- data[-row.number,]

# estimate the linear fit with the training set
multi.lm.fit0.8_1 <- lm(Hrs_Sleep~Age_Alc  +
                                    Age_Weed + 
                                    age_sex +
                                    race, 
                      data=train)
summary(multi.lm.fit0.8_1)

# predict on testing set
prediction.multi0.8_1 <- predict(multi.lm.fit0.8_1, newdata = test)
err0.8 <- prediction.multi0.8_1 - test$Hrs_Sleep
rmse <- sqrt(mean(err0.8^2))
mape <- mean(abs(err0.8/test$Hrs_Sleep))

c(RMSE=rmse,mape=mape,R2=summary(multi.lm.fit0.8_1)$r.squared)
```

Question 3b - Decision Tree 

```{r}

set.seed(997)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata3  <- data[sample, ]
testdata3   <- data[!sample, ]

model3b<-rpart(formula = Hrs_Sleep ~  Age_Alc + Age_Weed + race, data=traindata3, method = 'anova')

rpart.plot(model3b)



testdata3$modelPredicted3b <-predict(model3b, testdata3, type = 'vector')
testdata3


printcp(model3b)
plotcp(model3b)

rpart.rules(model3b)


```

Question 3c - Random Forest ------------ 

```{r}

set.seed(997)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata3  <- data[sample, ]
testdata3   <- data[!sample, ]

model3c<-randomForest(formula = Hrs_Sleep ~  Age_Alc + Age_Weed + age_sex + race, data = traindata3, proximity=TRUE, type='regression', na.action=na.exclude)
print(model3c)

testdata3$modelPredicted3c <-predict(model3c, testdata3)

plot(model3c)


```
Question 4


```{r}
set.seed(998)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata4  <- data[sample, ]
testdata4   <- data[!sample, ]


model4a <- lm(multiple_partners ~  Age_Alc + Age_Weed + age_sex + race, data=traindata4)

summary(model4a)

xkabledply(model4a, title = paste("Model :", format(formula(model4a)) ) )
xkablevif(model4a)


testdata4$modelPredicted4a <- predict(model4a, newdata = testdata4)
testdata4

# RESIDUALS ANALYSIS
# 
qqnorm(residuals(model4a))
qqline(residuals(model4a), col="red")

# shapiro.test(residuals(lm.fit))

# EVALUATE THE QUALITY OF THE MODEL
# 

# create a random training and a testing set
set.seed(1)
row.number <- sample(1:nrow(data), 0.8*nrow(data))

train <- data[row.number,]
test <- data[-row.number,]

# estimate the linear fit with the training set
multi.lm.fit0.8 <- lm(multiple_partners~Age_Alc  +
                                    Age_Weed + 
                                    age_sex +
                                    race, 
                      data=train)
summary(multi.lm.fit0.8)

# predict on testing set
prediction.multi0.8 <- predict(multi.lm.fit0.8, newdata = test)
err0.8 <- prediction.multi0.8 - test$multiple_partners
rmse <- sqrt(mean(err0.8^2))
mape <- mean(abs(err0.8/test$multiple_partners))

c(RMSE=rmse,mape=mape,R2=summary(multi.lm.fit0.8)$r.squared)
```

Question 4b - Decision Tree 

```{r}

set.seed(998)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata4  <- data[sample, ]
testdata4   <- data[!sample, ]

model4b<-rpart(formula = multiple_partners ~  Age_Alc + Age_Weed + race, data=traindata4, method = 'anova')

rpart.plot(model4b)



testdata4$modelPredicted4b <-predict(model4b, testdata4, type = 'vector')
testdata4


printcp(model4b)
plotcp(model4b)

rpart.rules(model4b)


```

Question 4c - Random Forest 

```{r}

set.seed(998)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata4  <- data[sample, ]
testdata4   <- data[!sample, ]

model4c<-randomForest(formula = multiple_partners ~  Age_Alc + Age_Weed + age_sex + race, data = traindata4, proximity=TRUE, type='regression', na.action=na.exclude)
print(model4c)

testdata4$modelPredicted4c <-predict(model4c, testdata4)


plot(model4c)


```

Question 5--------------------------

```{r}
set.seed(1027)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata5  <- data[sample, ]
testdata5   <- data[!sample, ]


model5a <- lm(physical_activity ~  Age_Alc + Age_Weed + age_sex + race, data=traindata5)
summary(model5a)
xkabledply(model5a, title = paste("Model :", format(formula(model5a)) ) )
xkablevif(model5a)


testdata5$modelPredicted5a <- predict(model5a, newdata = testdata5)
testdata5

# RESIDUALS ANALYSIS
# 
qqnorm(residuals(model5a))
qqline(residuals(model5a), col="red")

# shapiro.test(residuals(lm.fit)

# EVALUATE THE QUALITY OF THE MODEL
# 

# create a random training and a testing set
set.seed(1)
row.number <- sample(1:nrow(data), 0.8*nrow(data))

train <- data[row.number,]
test <- data[-row.number,]

# estimate the linear fit with the training set
multi.lm.fit0.8_2 <- lm(physical_activity~Age_Alc  +
                                    Age_Weed + 
                                    age_sex +
                                    race, 
                      data=train)
summary(multi.lm.fit0.8_2)

# predict on testing set
prediction.multi0.8_2 <- predict(multi.lm.fit0.8_2, newdata = test)
err0.8 <- prediction.multi0.8_2 - test$physical_activity
rmse <- sqrt(mean(err0.8^2))
mape <- mean(abs(err0.8/test$physical_activity))

c(RMSE=rmse,mape=mape,R2=summary(multi.lm.fit0.8_2)$r.squared)
```

Question 5b - Decision Tree 

```{r}

set.seed(1027)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata5  <- data[sample, ]
testdata5   <- data[!sample, ]

model5b<-rpart(formula = physical_activity ~  Age_Alc + Age_Weed + race, data=traindata5, method = 'anova')

rpart.plot(model5b)



testdata5$modelPredicted5b <-predict(model5b, testdata5, type = 'vector')
testdata5$modelPredicted5b


printcp(model5b)
plotcp(model5b)


rpart.rules(model5b)


```

Question 5c - Random Forest 

```{r}

set.seed(1027)
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8,0.2))
traindata5  <- data[sample, ]
testdata5   <- data[!sample, ]

model5c<-randomForest(formula = physical_activity ~  Age_Alc + Age_Weed + age_sex + race, data = traindata5, proximity=TRUE, type='regression', na.action=na.exclude)
print(model5c)

testdata5$modelPredicted5c <-predict(model5c, testdata5)

plot(model5c)


```